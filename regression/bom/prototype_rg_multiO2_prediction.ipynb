{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype Model\n",
    "---\n",
    "\n",
    "* Regression\n",
    "* 2009 data로 class1,2,3 10fold\n",
    "\n",
    "\n",
    "https://docs.google.com/presentation/d/1cI3teBcQoGBhfrdVrv9rnM4jHGaPToDS7Zh7t0q7GKg/edit#slide=id.g97e66187c6_0_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed as random_seed\n",
    "random_seed(50)\n",
    "from numpy.random import seed as np_random_seed\n",
    "np_random_seed(50)\n",
    "\n",
    "tf.random.set_seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/sgcwhb/Malocclusion/regression/bom',\n",
       " '/root/miniconda3/lib/python37.zip',\n",
       " '/root/miniconda3/lib/python3.7',\n",
       " '/root/miniconda3/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/root/miniconda3/lib/python3.7/site-packages',\n",
       " '/root/miniconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " '/docker_mnt/data5/jin/jin/python/']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.sys.path.append(r'/docker_mnt/data5/jin/jin/python/')\n",
    "\n",
    "os.sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7459116115287420600,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 1908086357995640673\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 48242412749\n",
       " locality {\n",
       "   bus_id: 2\n",
       "   numa_node: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5684189838859528999\n",
       " physical_device_desc: \"device: 0, name: Quadro RTX 8000, pci bus id: 0000:da:00.0, compute capability: 7.5\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 11889434353793838259\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=0\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=0\n",
    "from random import seed as random_seed\n",
    "random_seed(42)\n",
    "from numpy.random import seed as np_random_seed\n",
    "np_random_seed(42)\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Data Science\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, activations, initializers, regularizers, optimizers, losses, callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '../../results/fixed/2_10fold_prototypr_rg_multi02_so_img/so_rl/weights/'\n"
     ]
    }
   ],
   "source": [
    "so_type = 'so_rl'\n",
    "\n",
    "input_path_root = r'../../data/input_data/'\n",
    "\n",
    "# <model 저장>\n",
    "# output_path_root = r'../results/'\n",
    "output_path_root = r'../../results/fixed/2_10fold_prototypr_rg_multi02_so_img/'\n",
    "output_path = os.path.join(output_path_root,  so_type)\n",
    "output_path_weight = os.path.join(output_path, r'weights/')\n",
    "\n",
    "try:\n",
    "    os.makedirs(output_path_weight) \n",
    "    \n",
    "except FileExistsError as err:      \n",
    "    print(err)\n",
    "# else:\n",
    "#     print(output_path)\n",
    "#     print(output_path_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/input_data/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../results/fixed/2_10fold_prototypr_rg_multi02_so_img/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "---\n",
    "- Class 0 : 분별하기 어려운 data (65 sample) -> 제외\n",
    "\n",
    "- Class 3 : 하악이 상악보다 앞으로 돌출된 경우 (1136 sample) -> -1.0\n",
    "- Class 1 : 상하악의 맞물림 상태는 정상이지만 치열이 고르지 않은 경우 (1707 sample) -> 0.0\n",
    "- Class 2 : 상악이 하악보다 앞으로 돌출된 경우 (1175 sample) -> 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_class2reg(label_df):\n",
    "    label_r = np.copy(label_df.angle_class_r)\n",
    "    label_df.loc[label_r == 1, 'angle_class_r'] = 0\n",
    "    label_df.loc[label_r == 2, 'angle_class_r'] = 1\n",
    "    label_df.loc[label_r == 3, 'angle_class_r'] = -1\n",
    "    \n",
    "    label_l = np.copy(label_df.angle_class_l)\n",
    "    label_df.loc[label_l == 1, 'angle_class_l'] = 0\n",
    "    label_df.loc[label_l == 2, 'angle_class_l'] = 1\n",
    "    label_df.loc[label_l == 3, 'angle_class_l'] = -1\n",
    "    \n",
    "    return label_df\n",
    "\n",
    "def generate_data_by_patient(x, y): #y_distance):\n",
    "    if x.shape[-1] == 12:\n",
    "        x = np.concatenate([x[..., :3], x[..., 3:6], x[..., 6:9], x[..., 9:]]) \n",
    "        y = np.concatenate([y[:, 0], y[:, 1], y[:, 2], y[:, 3]])\n",
    "    elif x.shape[-1] == 6:\n",
    "        x = np.concatenate([x[..., :3], x[..., 3:]]) # Right side,Left side !!!\n",
    "        \n",
    "        y_r_test= to_categorical(y[:,0], num_classes=3)\n",
    "        y_l_test= to_categorical(y[:,1], num_classes=3)\n",
    "        \n",
    "        y = np.concatenate([y[:, 0], y[:, 1]])\n",
    "        y_onehot=np.concatenate((y_r_test,y_l_test),axis=0)\n",
    "        \n",
    "#         y_distance = np.concatenate([y_distance[:, 0], y_distance[:, 1]])\n",
    "    \n",
    "    return x, y, y_onehot #, y_distance\n",
    "\n",
    "# def generate_info_df_by_patient(info_df):\n",
    "#     info_df_r = info_df.copy()\n",
    "#     for row_idx, info in enumerate(info_df_r['info']):\n",
    "#         info_df_r.iloc[row_idx] = info + '_r'\n",
    "        \n",
    "#     info_df_l = info_df.copy()\n",
    "#     for row_idx, info in enumerate(info_df_l['info']):\n",
    "#         info_df_l.iloc[row_idx] = info + '_l'\n",
    "    \n",
    "#     info_df = pd.concat((info_df_r, info_df_l), ignore_index=True)\n",
    "#     del info_df_r, info_df_l\n",
    "    \n",
    "#     info_df1 = info_df.copy()\n",
    "        \n",
    "#     info_df2 = info_df.copy()\n",
    "#     for row_idx, info in enumerate(info_df2['info']):\n",
    "#         info_df2.iloc[row_idx] = info.replace('01A1', '02B1')\n",
    "    \n",
    "#     info_df = pd.concat((info_df1, info_df2), ignore_index=True)\n",
    "#     del info_df1, info_df2\n",
    "\n",
    "#     return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(os.path.join(input_path_root, f'data_KNU_Diorco_so_imgs.npy'))\n",
    "label_df = pd.read_csv(os.path.join(input_path_root, f'data_Diorco_label.csv'))\n",
    "label_df = convert_label_class2reg(label_df)\n",
    "\n",
    "y = label_df.loc[:, ['angle_class_r', 'angle_class_l']].to_numpy()\n",
    "y_distance= label_df.loc[:, ['distance(r)', 'distance(l)']].to_numpy()\n",
    "\n",
    "x = x.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "y_distance = y_distance.astype(np.float32)\n",
    "\n",
    "x = x / 127.5\n",
    "x = x - 1.\n",
    "\n",
    "#x = np.concatenate((x[::2, ...], x[1::2, ...]), axis=3)\n",
    "#y = np.concatenate((y[::2, ...], y[1::2, ...]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>tx_phase</th>\n",
       "      <th>angle_class_r</th>\n",
       "      <th>angle_class_l</th>\n",
       "      <th>distance(r)</th>\n",
       "      <th>distance(l)</th>\n",
       "      <th>one-hot-r</th>\n",
       "      <th>one-hot-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QH0026</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.23</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QH0026</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.10</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QH0041</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.88</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QH0041</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.05</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QH0044</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.94</td>\n",
       "      <td>4.63</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>QH1058</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>QH1072</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>QH1072</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.41</td>\n",
       "      <td>5.26</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>QH1084</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>QH1084</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2009 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id tx_phase  angle_class_r  angle_class_l  distance(r)  \\\n",
       "0        QH0026   Pre-Tx              0              0         1.48   \n",
       "1        QH0026  Post-Tx              0              1         1.22   \n",
       "2        QH0041   Pre-Tx              1              0         2.57   \n",
       "3        QH0041  Post-Tx              1              0         3.58   \n",
       "4        QH0044   Pre-Tx              1              1         6.94   \n",
       "...         ...      ...            ...            ...          ...   \n",
       "2004     QH1058  Post-Tx              0              0         2.00   \n",
       "2005     QH1072   Pre-Tx             -1             -1        -4.99   \n",
       "2006     QH1072  Post-Tx              1              1         7.41   \n",
       "2007     QH1084   Pre-Tx              0             -1        -0.55   \n",
       "2008     QH1084  Post-Tx              0              0        -0.46   \n",
       "\n",
       "      distance(l)        one-hot-r        one-hot-l  \n",
       "0            1.23  [1.0, 0.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "1            2.10  [1.0, 0.0, 0.0]  [0.0, 1.0, 0.0]  \n",
       "2            0.88  [0.0, 1.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "3            1.05  [0.0, 1.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "4            4.63  [0.0, 1.0, 0.0]  [0.0, 1.0, 0.0]  \n",
       "...           ...              ...              ...  \n",
       "2004         1.00  [1.0, 0.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "2005        -2.83  [0.0, 0.0, 1.0]  [0.0, 0.0, 1.0]  \n",
       "2006         5.26  [0.0, 1.0, 0.0]  [0.0, 1.0, 0.0]  \n",
       "2007        -0.55  [1.0, 0.0, 0.0]  [0.0, 0.0, 1.0]  \n",
       "2008        -0.00  [1.0, 0.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "\n",
       "[2009 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------onehot function test------------------\n",
    "x_tt, y_tt, y_onehot_tt=generate_data_by_patient(x,y)\n",
    "\n",
    "y_onehot_tt_r=y_onehot_tt[:(y_onehot_tt.shape[0]//2)]\n",
    "y_onehot_tt_l=y_onehot_tt[(y_onehot_tt.shape[0]//2):]\n",
    "\n",
    "y_onehot_tt_r=list(y_onehot_tt_r)\n",
    "y_onehot_tt_l=list(y_onehot_tt_l)\n",
    "\n",
    "\n",
    "label_df[\"one-hot-r\"]=y_onehot_tt_r\n",
    "label_df[\"one-hot-l\"]=y_onehot_tt_l\n",
    "label_df\n",
    "#---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (2009, 480, 784, 6)\n",
      "float32 (2009, 2)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2009 entries, 0 to 2008\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   patient_id     2009 non-null   object \n",
      " 1   tx_phase       2009 non-null   object \n",
      " 2   angle_class_r  2009 non-null   int64  \n",
      " 3   angle_class_l  2009 non-null   int64  \n",
      " 4   distance(r)    2009 non-null   float64\n",
      " 5   distance(l)    2009 non-null   float64\n",
      " 6   one-hot-r      2009 non-null   object \n",
      " 7   one-hot-l      2009 non-null   object \n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 125.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>tx_phase</th>\n",
       "      <th>angle_class_r</th>\n",
       "      <th>angle_class_l</th>\n",
       "      <th>distance(r)</th>\n",
       "      <th>distance(l)</th>\n",
       "      <th>one-hot-r</th>\n",
       "      <th>one-hot-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QH0026</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.23</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QH0026</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.10</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QH0041</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.88</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QH0041</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.05</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QH0044</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.94</td>\n",
       "      <td>4.63</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>QH1058</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>QH1072</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>QH1072</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.41</td>\n",
       "      <td>5.26</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>QH1084</td>\n",
       "      <td>Pre-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>QH1084</td>\n",
       "      <td>Post-Tx</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2009 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id tx_phase  angle_class_r  angle_class_l  distance(r)  \\\n",
       "0        QH0026   Pre-Tx              0              0         1.48   \n",
       "1        QH0026  Post-Tx              0              1         1.22   \n",
       "2        QH0041   Pre-Tx              1              0         2.57   \n",
       "3        QH0041  Post-Tx              1              0         3.58   \n",
       "4        QH0044   Pre-Tx              1              1         6.94   \n",
       "...         ...      ...            ...            ...          ...   \n",
       "2004     QH1058  Post-Tx              0              0         2.00   \n",
       "2005     QH1072   Pre-Tx             -1             -1        -4.99   \n",
       "2006     QH1072  Post-Tx              1              1         7.41   \n",
       "2007     QH1084   Pre-Tx              0             -1        -0.55   \n",
       "2008     QH1084  Post-Tx              0              0        -0.46   \n",
       "\n",
       "      distance(l)        one-hot-r        one-hot-l  \n",
       "0            1.23  [1.0, 0.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "1            2.10  [1.0, 0.0, 0.0]  [0.0, 1.0, 0.0]  \n",
       "2            0.88  [0.0, 1.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "3            1.05  [0.0, 1.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "4            4.63  [0.0, 1.0, 0.0]  [0.0, 1.0, 0.0]  \n",
       "...           ...              ...              ...  \n",
       "2004         1.00  [1.0, 0.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "2005        -2.83  [0.0, 0.0, 1.0]  [0.0, 0.0, 1.0]  \n",
       "2006         5.26  [0.0, 1.0, 0.0]  [0.0, 1.0, 0.0]  \n",
       "2007        -0.55  [1.0, 0.0, 0.0]  [0.0, 0.0, 1.0]  \n",
       "2008        -0.00  [1.0, 0.0, 0.0]  [1.0, 0.0, 0.0]  \n",
       "\n",
       "[2009 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x.dtype, x.shape)\n",
    "print(y.dtype, y.shape)\n",
    "print()\n",
    "display.display(label_df.info())\n",
    "display.display(label_df)\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure()\n",
    "\n",
    "plt.title('Label')\n",
    "sns.countplot(np.concatenate([label_df.angle_class_r, label_df.angle_class_l]))\n",
    "\n",
    "plt.show()\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calss -1: 1136\n",
      "calss 0: 1707\n",
      "calss 1: 1175\n"
     ]
    }
   ],
   "source": [
    "cnt = np.concatenate([label_df.angle_class_r, label_df.angle_class_l])\n",
    "\n",
    "\n",
    "print(\"calss -1:\",len(cnt[cnt==-1]))\n",
    "print(\"calss 0:\",len(cnt[cnt==0]))\n",
    "print(\"calss 1:\",len(cnt[cnt==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = InceptionResNetV2(include_top=False, weights=None, input_shape=(None, None, 3))\n",
    "\n",
    "#     base_model.trainable = False\n",
    "\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "\n",
    "    # base_model.summary()\n",
    "\n",
    "    x = base_model.output\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='gap')(x)\n",
    "    x = layers.Dense(256, activation='relu', name='dense')(x)\n",
    "    x = layers.Dropout(0.2, name='dropout')(x)\n",
    "    \n",
    "    regression_prediction=layers.Dense(1, name='regression_prediction')(x)\n",
    "    one_hot_prediction=layers.Dense(3, activation='softmax', name='classification')(regression_prediction)\n",
    "#     distance_prediction=layers.Dense(1, name='distance_prediction')(x)\n",
    "\n",
    "    \n",
    "    model = models.Model(inputs=base_model.input, outputs=[regression_prediction,one_hot_prediction])\n",
    "#     model = models.Model(inputs=base_model.input, outputs=[regression_prediction,one_hot_prediction,distance_prediction])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 3 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, None, 3 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 6 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, None, None, 6 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 8 5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 8 240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 8 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 1 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 9 55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 4 144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 9 288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 4 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 9 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, None, None, 1 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 9 18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 6 76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 6 12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 9 288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 6 192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 9 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 6 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, None, None, 3 0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 3 96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 3 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 4 13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 3 96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 4 144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 3 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 4 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 3 9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 6 27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 3 96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 6 192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 3 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 6 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, None, None, 1 0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, None, None, 3 41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, None, None, 3 0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, None, None, 3 0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 3 96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 3 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 4 13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 3 96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 4 144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 3 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 4 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 3 9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 3 96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 3 96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 3 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 3 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, None, None, 1 0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, None, None, 3 41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, None, None, 3 0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, None, None, 3 0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 4 13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 3 96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 4 144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 3 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 4 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 3 9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 6 27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 3 96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 3 96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 6 192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 3 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 3 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 6 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, None, None, 1 0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, None, None, 3 41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, None, None, 3 0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, None, None, 3 0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 3 96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 3 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 4 13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 3 96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 4 144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 3 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 4 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 3 9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 6 27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 3 96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 3 96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 6 192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 3 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 3 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 6 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, None, None, 1 0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, None, None, 3 41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, None, None, 3 0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, None, None, 3 0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 3 96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 3 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 4 13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 3 96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 4 144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 3 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 4 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 3 9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 6 27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 3 96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 3 96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 6 192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 3 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 3 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 6 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, None, None, 1 0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, None, None, 3 41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, None, None, 3 0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, None, None, 3 0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 3 96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 3 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 4 13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 3 96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 4 144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 3 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 4 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 3 9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 6 27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 3 96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 3 96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 6 192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 3 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 3 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 6 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, None, None, 1 0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, None, None, 3 41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, None, None, 3 0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, None, None, 3 0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 3 96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 3 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 4 13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 3 96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 4 144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 3 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 4 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 3 9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 6 27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 3 96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 3 96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 6 192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 3 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 3 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 6 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, None, None, 1 0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, None, None, 3 41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, None, None, 3 0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, None, None, 3 0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 3 96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 3 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 4 13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 3 96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 4 144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 3 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 4 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 3 9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 6 27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 3 96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 3 96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 6 192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 3 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 3 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 6 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, None, None, 1 0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, None, None, 3 41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, None, None, 3 0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, None, None, 3 0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 3 96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 3 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 4 13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 3 96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 4 144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 3 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 4 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 3 9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 6 27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 3 96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 3 96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 6 192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 3 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 3 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 6 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, None, None, 1 0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, None, None, 3 41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, None, None, 3 0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, None, None, 3 0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 3 96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 3 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 4 13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 3 96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 4 144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 3 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 4 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 3 9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 6 27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 3 96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 3 96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 6 192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 3 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 3 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 6 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, None, None, 1 0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, None, None, 3 41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, None, None, 3 0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, None, None, 3 0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 2 81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 2 768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 2 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 2 589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 2 768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 2 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 3 884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 3 1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 3 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 3 0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 1 139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 1 384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 1 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 1 143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 1 480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 1 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 1 215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 1 576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 1 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, None, None, 3 0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, None, None, 1 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, None, None, 1 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, None, None, 1 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 1 139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 1 384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 1 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 1 143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 1 480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 1 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 1 208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 1 215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 1 576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 1 576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 1 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 1 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, None, None, 3 0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, None, None, 1 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, None, None, 1 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, None, None, 1 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 1 143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 1 480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 1 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 1 208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 1 215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 1 576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 1 576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 1 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 1 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, None, None, 3 0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, None, None, 1 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, None, None, 1 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, None, None, 1 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 1 139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 1 384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 1 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 1 143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 1 480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 1 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 1 208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 1 215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 1 576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 1 576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 1 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 1 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, None, None, 3 0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, None, None, 1 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, None, None, 1 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, None, None, 1 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 1 139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 1 384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 1 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 1 208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, None, None, 1 215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 1 576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, None, 1 576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 1 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 1 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, None, None, 3 0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, None, None, 1 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, None, None, 1 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, None, None, 1 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, None, None, 1 139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, None, 1 384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 1 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, None, None, 1 143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, None, 1 480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, None, 1 0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, None, None, 1 208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, None, None, 1 215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, None, 1 576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, None, 1 576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 1 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, None, 1 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, None, None, 3 0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, None, None, 1 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, None, None, 1 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, None, None, 1 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, None, None, 1 139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, None, None, 1 384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, None, 1 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, None, None, 1 143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, None, None, 1 480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, None, 1 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, None, None, 1 208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, None, None, 1 215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, None, None, 1 576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, None, None, 1 576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, None, 1 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, None, 1 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, None, None, 3 0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, None, None, 1 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, None, None, 1 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, None, None, 1 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, None, None, 1 139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, None, None, 1 384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, None, 1 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, None, None, 1 143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, None, None, 1 480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, None, 1 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, None, None, 1 208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, None, None, 1 215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, None, None, 1 576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, None, None, 1 576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, None, 1 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, None, 1 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, None, None, 3 0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, None, None, 1 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, None, None, 1 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, None, None, 1 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, None, None, 1 139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, None, None, 1 384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, None, 1 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, None, None, 1 143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, None, None, 1 480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, None, 1 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, None, None, 1 208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, None, None, 1 215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, None, None, 1 576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, None, None, 1 576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, None, 1 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, None, 1 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, None, None, 3 0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, None, None, 1 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, None, None, 1 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, None, None, 1 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, None, None, 1 139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, None, None, 1 384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, None, 1 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, None, None, 1 143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, None, None, 1 480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, None, 1 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, None, None, 1 208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, None, None, 1 215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, None, None, 1 576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, None, None, 1 576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, None, 1 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, None, 1 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, None, None, 3 0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, None, None, 1 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, None, None, 1 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, None, None, 1 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, None, None, 1 139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, None, None, 1 384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, None, 1 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, None, None, 1 143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, None, None, 1 480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, None, 1 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, None, None, 1 208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, None, None, 1 215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, None, None, 1 576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, None, None, 1 576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, None, 1 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, None, 1 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, None, None, 3 0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, None, None, 1 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, None, None, 1 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, None, None, 1 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, None, None, 1 139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, None, None, 1 384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, None, 1 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, None, None, 1 143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, None, None, 1 480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, None, 1 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, None, None, 1 208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, None, None, 1 215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, None, None, 1 576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, None, None, 1 576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, None, 1 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, None, 1 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, None, None, 3 0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, None, None, 1 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, None, None, 1 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, None, None, 1 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, None, None, 1 139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, None, None, 1 384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, None, 1 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, None, None, 1 143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, None, None, 1 480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, None, 1 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, None, None, 1 208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, None, None, 1 215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, None, None, 1 576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, None, None, 1 576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, None, None, 1 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, None, 1 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, None, None, 3 0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, None, None, 1 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, None, None, 1 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, None, None, 1 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, None, None, 1 139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, None, None, 1 384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, None, 1 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, None, None, 1 143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, None, None, 1 480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, None, 1 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, None, None, 1 208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, None, None, 1 215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, None, None, 1 576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, None, None, 1 576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, None, 1 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, None, 1 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, None, None, 3 0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, None, None, 1 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, None, None, 1 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, None, None, 1 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, None, None, 1 139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, None, None, 1 384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, None, 1 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, None, None, 1 143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, None, None, 1 480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, None, 1 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, None, None, 1 208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, None, None, 1 215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, None, None, 1 576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, None, None, 1 576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, None, 1 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, None, 1 0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, None, None, 3 0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, None, None, 1 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, None, None, 1 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, None, None, 1 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, None, None, 1 139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, None, None, 1 384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, None, 1 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, None, None, 1 143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, None, None, 1 480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, None, 1 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, None, None, 1 208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, None, None, 1 215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, None, None, 1 576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, None, None, 1 576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, None, 1 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, None, 1 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, None, None, 3 0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, None, None, 1 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, None, None, 1 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, None, None, 1 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, None, None, 1 139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, None, None, 1 384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, None, None, 1 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, None, None, 1 143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, None, None, 1 480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, None, None, 1 0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, None, None, 1 208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, None, None, 1 215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, None, None, 1 576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, None, None, 1 576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, None, None, 1 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, None, None, 1 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, None, None, 3 0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, None, None, 1 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, None, None, 1 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, None, None, 1 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, None, None, 1 139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, None, None, 1 384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, None, None, 1 0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, None, None, 1 143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, None, None, 1 480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, None, None, 1 0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, None, None, 1 208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, None, None, 1 215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, None, None, 1 576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, None, None, 1 576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, None, None, 1 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, None, None, 1 0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, None, None, 3 0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, None, None, 1 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, None, None, 1 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, None, None, 1 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, None, None, 1 139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, None, None, 1 384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, None, None, 1 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, None, None, 1 143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, None, None, 1 480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, None, None, 1 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, None, None, 1 208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, None, None, 1 215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, None, None, 1 576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, None, None, 1 576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, None, None, 1 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, None, None, 1 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, None, None, 3 0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, None, None, 1 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, None, None, 1 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, None, None, 1 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, None, None, 1 139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, None, None, 1 384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, None, None, 1 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, None, None, 1 143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, None, None, 1 480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, None, None, 1 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, None, None, 1 208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, None, None, 1 215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, None, None, 1 576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, None, None, 1 576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, None, None, 1 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, None, None, 1 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, None, None, 3 0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, None, None, 1 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, None, None, 1 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, None, None, 1 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, None, None, 2 768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, None, None, 2 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, None, None, 2 663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, None, None, 2 768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, None, None, 2 768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, None, None, 2 864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, None, None, 2 0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, None, None, 2 0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, None, None, 2 0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, None, None, 3 884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, None, None, 2 663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, None, None, 3 829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, None, None, 3 1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, None, None, 2 864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, None, None, 3 960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, None, None, 3 0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, None, None, 2 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, None, None, 3 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, None, None, 2 0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, None, None, 1 576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, None, None, 1 0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, None, None, 2 129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, None, None, 2 672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, None, None, 2 0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, None, None, 2 172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, None, None, 1 576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, None, None, 2 768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, None, None, 1 0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, None, None, 2 0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, None, None, 4 0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, None, None, 2 933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, None, None, 2 0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, None, None, 2 0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, None, None, 1 576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, None, None, 1 0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, None, None, 2 129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, None, None, 2 672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, None, None, 2 0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, None, None, 2 172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, None, None, 1 576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, None, None, 2 768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, None, None, 1 0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, None, None, 2 0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, None, None, 4 0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, None, None, 2 933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, None, None, 2 0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, None, None, 2 0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, None, None, 1 576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, None, None, 1 0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, None, None, 2 129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, None, None, 2 672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, None, None, 2 0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, None, None, 2 172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, None, None, 1 576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, None, None, 2 768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, None, None, 1 0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, None, None, 2 0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, None, None, 4 0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, None, None, 2 933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, None, None, 2 0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, None, None, 2 0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, None, None, 1 576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, None, None, 1 0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, None, None, 2 129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, None, None, 2 672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, None, None, 2 0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, None, None, 2 172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, None, None, 1 576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, None, None, 2 768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, None, None, 1 0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, None, None, 2 0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, None, None, 4 0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, None, None, 2 933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, None, None, 2 0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, None, None, 2 0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, None, None, 1 576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, None, None, 1 0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, None, None, 2 129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, None, None, 2 672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, None, None, 2 0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, None, None, 2 172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, None, None, 1 576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, None, None, 2 768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, None, None, 1 0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, None, None, 2 0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, None, None, 4 0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, None, None, 2 933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, None, None, 2 0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, None, None, 2 0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, None, None, 1 576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, None, None, 1 0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, None, None, 2 129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, None, None, 2 672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, None, None, 2 0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, None, None, 2 172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, None, None, 1 576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, None, None, 2 768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, None, None, 1 0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, None, None, 2 0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, None, None, 4 0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, None, None, 2 933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, None, None, 2 0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, None, None, 2 0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, None, None, 1 576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, None, None, 1 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, None, None, 2 129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, None, None, 2 672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, None, None, 2 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, None, None, 2 172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, None, None, 1 576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, None, None, 2 768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, None, None, 1 0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, None, None, 2 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, None, None, 4 0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, None, None, 2 933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, None, None, 2 0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, None, None, 2 0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, None, None, 1 576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, None, None, 1 0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, None, None, 2 129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, None, None, 2 672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, None, None, 2 0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, None, None, 2 172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, None, None, 1 576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, None, None, 2 768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, None, None, 1 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, None, None, 2 0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, None, None, 4 0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, None, None, 2 933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, None, None, 2 0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, None, None, 2 0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, None, None, 1 576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, None, None, 1 0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, None, None, 2 129024      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, None, None, 2 672         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, None, None, 2 0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, None, None, 2 172032      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, None, None, 1 576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, None, None, 2 768         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, None, None, 1 0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, None, None, 2 0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, None, None, 4 0           activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, None, None, 2 933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, None, None, 2 0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, None, None, 2 0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, None, None, 1 576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, None, None, 1 0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, None, None, 2 129024      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, None, None, 2 672         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, None, None, 2 0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, None, None, 2 172032      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, None, None, 1 576         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, None, None, 2 768         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, None, None, 1 0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, None, None, 2 0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, None, None, 4 0           activation_199[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, None, None, 2 933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, None, None, 2 0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, None, None, 1 3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, None, None, 1 4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, None, None, 1 0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gap (GlobalAveragePooling2D)    (None, 1536)         0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          393472      gap[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "regression_prediction (Dense)   (None, 1)            257         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 3)            6           regression_prediction[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 54,730,471\n",
      "Trainable params: 54,669,927\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "#                       loss=[\"mae\",\"categorical_crossentropy\",\"mae\"],\n",
    "#                       metrics=[\"acc\",\"mae\"])\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "                      loss={'regression_prediction':\"mae\",'classification':\"categorical_crossentropy\"},\n",
    "                      metrics=[\"acc\",\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold CV: 06/10\n",
      "[  10   30   45   55   61   62   82   85  107  110  111  118  119  126\n",
      "  131  137  143  144  156  160  179  188  195  202  231  232  240  246\n",
      "  252  272  279  292  295  305  317  318  323  329  341  343  368  374\n",
      "  379  394  396  400  403  408  409  426  428  437  447  456  488  500\n",
      "  507  510  511  516  517  540  543  552  560  568  577  586  608  612\n",
      "  615  629  659  663  670  686  693  739  742  798  808  815  824  829\n",
      "  830  831  841  845  849  852  859  877  915  918  966  968  970  978\n",
      "  990 1005 1038 1044 1045 1062 1071 1072 1088 1105 1113 1115 1120 1130\n",
      " 1137 1139 1141 1146 1151 1154 1171 1186 1195 1200 1205 1210 1243 1259\n",
      " 1263 1266 1269 1280 1288 1292 1297 1301 1306 1350 1356 1358 1369 1398\n",
      " 1402 1409 1432 1436 1447 1473 1479 1480 1514 1515 1534 1536 1539 1550\n",
      " 1570 1616 1617 1646 1654 1657 1675 1682 1695 1701 1708 1721 1725 1728\n",
      " 1729 1733 1738 1758 1759 1765 1769 1787 1801 1803 1812 1830 1839 1842\n",
      " 1843 1844 1860 1866 1869 1885 1888 1921 1924 1942 1945 1948 1956 1970\n",
      " 1987 1990 1995 2003 2007]\n",
      "Train on 2892 samples, validate on 724 samples\n",
      "Epoch 1/100\n",
      "2892/2892 [==============================] - 210s 73ms/sample - loss: 1.7206 - regression_prediction_loss: 0.6180 - classification_loss: 1.1028 - regression_prediction_acc: 0.4302 - regression_prediction_mae: 0.6179 - classification_acc: 0.4236 - classification_mae: 0.4414 - val_loss: 1.6544 - val_regression_prediction_loss: 0.5804 - val_classification_loss: 1.0751 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5795 - val_classification_acc: 0.4503 - val_classification_mae: 0.4376\n",
      "Epoch 2/100\n",
      "2892/2892 [==============================] - 187s 65ms/sample - loss: 1.5926 - regression_prediction_loss: 0.5334 - classification_loss: 1.0582 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5342 - classification_acc: 0.4948 - classification_mae: 0.4316 - val_loss: 2.2636 - val_regression_prediction_loss: 1.0050 - val_classification_loss: 1.2595 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 1.0036 - val_classification_acc: 0.2928 - val_classification_mae: 0.4572\n",
      "Epoch 3/100\n",
      "2892/2892 [==============================] - 185s 64ms/sample - loss: 1.6512 - regression_prediction_loss: 0.5722 - classification_loss: 1.0788 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5723 - classification_acc: 0.4302 - classification_mae: 0.4354 - val_loss: 1.6686 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0846 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4369\n",
      "Epoch 4/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5702 - classification_loss: 1.0786 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6693 - val_regression_prediction_loss: 0.5859 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5850 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 5/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6443 - regression_prediction_loss: 0.5686 - classification_loss: 1.0756 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5687 - classification_acc: 0.4357 - classification_mae: 0.4346 - val_loss: 1.8457 - val_regression_prediction_loss: 0.7406 - val_classification_loss: 1.1062 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.7396 - val_classification_acc: 0.3301 - val_classification_mae: 0.4450\n",
      "Epoch 6/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 7/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 8/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 9/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4353 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 10/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 11/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5695 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6693 - val_regression_prediction_loss: 0.5857 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5848 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 12/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6692 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 13/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 14/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5689 - classification_loss: 1.0780 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 15/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5846 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 16/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 17/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5703 - classification_loss: 1.0786 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4362\n",
      "Epoch 18/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5692 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 19/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 20/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 21/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5692 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 22/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 23/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5693 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4353 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 24/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5692 - classification_loss: 1.0780 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 25/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5693 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 26/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 27/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 28/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 29/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 30/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6695 - val_regression_prediction_loss: 0.5859 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5850 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 31/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 32/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 33/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 34/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 35/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 36/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 37/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 38/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 39/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 40/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5697 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 41/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 42/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 43/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5695 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 44/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 45/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5692 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 46/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 47/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4346 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 48/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6696 - val_regression_prediction_loss: 0.5860 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5851 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 49/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 50/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 51/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5697 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5846 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 52/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 53/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0850 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 54/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 55/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6481 - regression_prediction_loss: 0.5697 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5698 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 56/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 57/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5846 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 58/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 59/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6690 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 60/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5693 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 61/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5702 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 62/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5692 - classification_loss: 1.0781 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 63/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6694 - val_regression_prediction_loss: 0.5859 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5850 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 64/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4352 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 65/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5700 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 66/100\n",
      "2892/2892 [==============================] - 184s 64ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 67/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 68/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5689 - classification_loss: 1.0779 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4366\n",
      "Epoch 69/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6687 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 70/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5703 - classification_loss: 1.0785 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4348 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5845 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 71/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6686 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0846 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4367\n",
      "Epoch 72/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5696 - classification_acc: 0.4305 - classification_mae: 0.4350 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5854 - val_classification_loss: 1.0847 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 73/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0783 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4356 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4363\n",
      "Epoch 74/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4349 - val_loss: 1.6691 - val_regression_prediction_loss: 0.5855 - val_classification_loss: 1.0849 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5846 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 75/100\n",
      "2892/2892 [==============================] - 183s 63ms/sample - loss: 1.6479 - regression_prediction_loss: 0.5699 - classification_loss: 1.0784 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4347 - val_loss: 1.6688 - val_regression_prediction_loss: 0.5852 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5843 - val_classification_acc: 0.4157 - val_classification_mae: 0.4365\n",
      "Epoch 76/100\n",
      "2892/2892 [==============================] - 184s 63ms/sample - loss: 1.6480 - regression_prediction_loss: 0.5696 - classification_loss: 1.0782 - regression_prediction_acc: 0.4305 - regression_prediction_mae: 0.5697 - classification_acc: 0.4305 - classification_mae: 0.4351 - val_loss: 1.6689 - val_regression_prediction_loss: 0.5853 - val_classification_loss: 1.0848 - val_regression_prediction_acc: 0.4157 - val_regression_prediction_mae: 0.5844 - val_classification_acc: 0.4157 - val_classification_mae: 0.4364\n",
      "Epoch 77/100\n",
      "2888/2892 [============================>.] - ETA: 0s - loss: 1.6476 - regression_prediction_loss: 0.5694 - classification_loss: 1.0782 - regression_prediction_acc: 0.4307 - regression_prediction_mae: 0.5694 - classification_acc: 0.4307 - classification_mae: 0.4349"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mmake_logs\u001b[0;34m(model, logs, outputs, mode, prefix)\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0;34m\"\"\"Computes logs for sending to `on_batch_end` methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m   \u001b[0mmetric_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmetric_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;31m# Add all metric names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0mmetrics_names\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_metrics_from_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_metrics_from_layers\u001b[0;34m(layers)\u001b[0m\n\u001b[1;32m   3232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3233\u001b[0;31m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3234\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_children_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1af5e1883d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                       total_epochs=1)\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    769\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m       \u001b[0;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                   int) or self.epochs_since_last_save >= self.period:\n\u001b[1;32m   1010\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_get_file_path\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     if not self.model._in_multi_worker_mode(\n\u001b[1;32m   1054\u001b[0m     ) or multi_worker_util.should_save_checkpoint():\n\u001b[0;32m-> 1055\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m       \u001b[0;31m# If this is multi-worker training, and this worker should not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_testidx=[]\n",
    "\n",
    "for kfold_idx, (train_idxs, test_idxs) in enumerate(kfold.split(x, y[:, 0])): #left???\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    print(f'K-Fold CV: {kfold_idx + 1:02d}/{kfold.n_splits:02d}')\n",
    "\n",
    "    # 1. Data\n",
    "    # ----------------------------------------\n",
    "\n",
    "#------DEBUG--------:\n",
    "    print(test_idxs)\n",
    "    fold_testidx.append(test_idxs)\n",
    "#     print(np.unique(y[test_idxs, 0], return_counts=True))\n",
    "#-------------------   \n",
    "\n",
    "    x_train = x[train_idxs]\n",
    "    y_train = y[train_idxs]\n",
    "    label_df_train = label_df.iloc[train_idxs]\n",
    "\n",
    "    x_train, x_val, y_train, y_val, label_df_train, label_df_val = train_test_split(x_train, y_train, label_df_train, test_size=0.2, \n",
    "                                                                                    random_state=42, stratify=y_train[:, 0])\n",
    "\n",
    "    x_test = x[test_idxs]\n",
    "    y_test = y[test_idxs]\n",
    "    label_df_test = label_df.iloc[test_idxs]\n",
    "\n",
    "    #distance 누락!\n",
    "    x_train, y_train,y_train_onehot = generate_data_by_patient(x_train, y_train)\n",
    "    x_val, y_val, y_val_onehot = generate_data_by_patient(x_val, y_val)\n",
    "    x_test, y_test, y_test_onehot = generate_data_by_patient(x_test, y_test)\n",
    "\n",
    "    weight_for_m1 = (1 / len(y_train[y_train==-1]))*(len(y_train))/3.0 \n",
    "    weight_for_0 = (1 / len(y_train[y_train==0]))*(len(y_train))/3.0 \n",
    "    weight_for_1 = (1 / len(y_train[y_train==1]))*(len(y_train))/3.0\n",
    "\n",
    "    class_weight=[weight_for_m1,weight_for_0,weight_for_1]\n",
    "\n",
    "#------DEBUG--------:\n",
    "#     print(len(y_train))\n",
    "#     print(\"class -1;\",len(y_train[y_train==-1]))\n",
    "#     print(\"class 0;\",len(y_train[y_train==0]))\n",
    "#     print(\"class 1;\",len(y_train[y_train==1]))\n",
    "\n",
    "#     print(\"-------------\")\n",
    "#     print(weight_for_m1)\n",
    "#     print(weight_for_0)\n",
    "#     print(weight_for_1)\n",
    "\n",
    "#------------------- \n",
    "\n",
    "\n",
    "    # DEBUG:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     data_idx1 = 1\n",
    "#     plt.title(info_train.iloc[data_idx1, 0])\n",
    "#     plt.imshow((x_train[data_idx1] + 1) / 2)\n",
    "#     plt.xlabel(f'Label: {y_train[data_idx1]}')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     data_idx2 = data_idx1 + len(x_train) // 4\n",
    "#     plt.title(info_train.iloc[data_idx2, 0])\n",
    "#     plt.imshow((x_train[data_idx2] + 1) / 2)\n",
    "#     plt.xlabel(f'Label: {y_train[data_idx2]}')\n",
    "\n",
    "#     plt.show()\n",
    "#     print(x_train.dtype, x_train.shape)\n",
    "#     print(y_train.dtype, y_train.shape)\n",
    "#     print()\n",
    "#     print(x_val.dtype, x_val.shape)\n",
    "#     print(y_val.dtype, y_val.shape)\n",
    "#     print()\n",
    "#     print(x_test.dtype, x_test.shape)\n",
    "#     print(y_test.dtype, y_test.shape)\n",
    "\n",
    "    # 2. Paths\n",
    "    # ----------------------------------------\n",
    "\n",
    "    output_path_kfold = os.path.join(output_path, f'kfold_{kfold_idx + 1:02d}/')\n",
    "    output_path_weight = os.path.join(output_path_kfold, r'weights/')\n",
    "\n",
    "    if os.path.isdir(output_path_weight)==False:\n",
    "        os.makedirs(output_path_weight)\n",
    "\n",
    "    # 3. Build a Model.\n",
    "    # ----------------------------------------\n",
    "\n",
    "    if kfold_idx == 0:\n",
    "        model = build_model()\n",
    "\n",
    "        model.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "                      loss={'regression_prediction':\"mae\",'classification':\"categorical_crossentropy\"},\n",
    "                      loss_weights={'regression_prediction':1,'classification':1},\n",
    "                      metrics=[\"acc\",\"mae\"])\n",
    "\n",
    "        model.save(os.path.join(output_path, r'model.hdf5'))\n",
    "\n",
    "        # model.summary()\n",
    "    else:\n",
    "        model = models.load_model(os.path.join(output_path, r'model.hdf5'))\n",
    "\n",
    "    # 4. Train the Model.\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # Callbacks\n",
    "    checkpointer = callbacks.ModelCheckpoint(os.path.join(output_path_weight, 'weights_{epoch:08d}_{val_loss:.4g}.hdf5'),\n",
    "                                             save_weights_only=True)\n",
    "    csv_logger = callbacks.CSVLogger(os.path.join(output_path_kfold, r'log.csv'), append=True)\n",
    "\n",
    "\n",
    "    # Training batch size 16 -> 8\n",
    "    model.fit(x_train,{'regression_prediction':y_train, 'classification':y_train_onehot},\n",
    "              batch_size=8,\n",
    "              epochs=100,\n",
    "              validation_data=(x_val, {'regression_prediction':y_val,'classification':y_val_onehot}),\n",
    "              callbacks=[checkpointer, csv_logger],\n",
    "              initial_epoch=0,\n",
    "              class_weight=[class_weight,class_weight],\n",
    "              verbose=1)\n",
    "\n",
    "    K.clear_session()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = label_df.copy()\n",
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.iloc[[0,3,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "predictions_kfold = []\n",
    "labels_kfold = []\n",
    "distance_regression = [] \n",
    "\n",
    "total_info =[]\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# model_parm_name=\"D\"+depth+\"_\"+dropout_rat\n",
    "\n",
    "for kfold_idx, (train_idxs, test_idxs) in enumerate(kfold.split(x, y[:, 0])):\n",
    "    print(f'K-Fold CV: {kfold_idx + 1:02d}/{kfold.n_splits:02d}')\n",
    "    \n",
    "    # 1. Data\n",
    "    # ----------------------------------------\n",
    "    \n",
    "    if kfold_idx==0:\n",
    "\n",
    "        x_test = x[test_idxs]\n",
    "        y_test = y[test_idxs]\n",
    "\n",
    "        label_df_test = label_df.iloc[test_idxs]\n",
    "\n",
    "        x_test, y_test, y_test_onehot = generate_data_by_patient(x_test, y_test)\n",
    "\n",
    "        # 2. Paths\n",
    "        # ----------------------------------------\n",
    "\n",
    "    #     output_path_kfold = os.path.join(output_path, model_parm_name, f'kfold_{kfold_idx + 1:02d}/')\n",
    "        output_path_kfold = os.path.join(output_path,  f'kfold_{kfold_idx + 1:02d}/')\n",
    "        output_path_weight = os.path.join(output_path_kfold, r'weights/')\n",
    "\n",
    "        # 3. Plot Learning Curves.\n",
    "        # ----------------------------------------\n",
    "\n",
    "        # log 저장: loss, mae, val_loss, val_mae\n",
    "        log_df = pd.read_csv(os.path.join(output_path_kfold, r'log.csv'))\n",
    "\n",
    "\n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "        plt.figure(figsize=(25, 6))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.title(f'Learning Curves ({kfold_idx + 1:02d}/{kfold.n_splits:02d})')\n",
    "        plt.plot(log_df.loss)\n",
    "        plt.plot(log_df.val_loss)\n",
    "        plt.legend(('Train Loss', 'Validation Loss'))\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.plot(log_df.classification_acc)\n",
    "        plt.plot(log_df.val_classification_acc)\n",
    "        plt.ylim(0, 1.5)\n",
    "        plt.legend(('Train Classification MAE', 'Validation Classification MAE'))\n",
    "\n",
    "#         plt.subplot(2,2,3)\n",
    "#         plt.plot(log_df.distance_prediction_mae)\n",
    "#         plt.plot(log_df.val_distance_prediction_mae)\n",
    "#         plt.ylim(0, 1.5)\n",
    "#         plt.legend(('Train distance Classification MAE', 'Validation distance Classification MAE'))\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.plot(log_df.regression_prediction_mae)\n",
    "        plt.plot(log_df.val_regression_prediction_mae)\n",
    "        plt.ylim(0, 1.5)\n",
    "        plt.legend(('Train regression Classification MAE', 'Validation regression Classification MAE'))\n",
    "\n",
    "        plt.show()\n",
    "        plt.style.use('seaborn-white')\n",
    "        print(f'Min. validation loss epoch: {log_df.val_loss.idxmin() + 1}')\n",
    "        print(f'Max. Classification MAE epoch: {log_df.val_classification_acc.idxmax() + 1}')\n",
    "#         print(f'Max. distance validation MAE epoch: {log_df.val_distance_prediction_mae.idxmax() + 1}')\n",
    "        print(f'Max. regression validation MAE epoch: {log_df.val_regression_prediction_mae.idxmax() + 1}')\n",
    "\n",
    "\n",
    "\n",
    "        info_df = label_df.copy()\n",
    "\n",
    "        result_info_df = info_df.iloc[test_idxs]\n",
    "\n",
    "        inference_df = result_info_df.copy()\n",
    "\n",
    "        # 4. Load a Model.\n",
    "        # ----------------------------------------\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        #sgcwhb/Malocclusion/results/prototype_regression_so_img/so_rl/model.hdf5\n",
    "        model = models.load_model(os.path.join(output_path, r'model.hdf5'))\n",
    "        #validation mae가 가장 적은 model weight load\n",
    "        model.load_weights(glob.glob(os.path.join(output_path_weight, f'weights_{log_df.val_loss.idxmin() + 1:08d}*.hdf5'))[0])\n",
    "\n",
    "        # 5. Display\n",
    "        # ----------------------------------------\n",
    "\n",
    "\n",
    "        prediction = model.predict(x_test)\n",
    "\n",
    "        prediction_distance_r = prediction[0][:int(prediction[0].shape[0]/2),0] #Right\n",
    "        prediction_distance_l = prediction[0][int(prediction[0].shape[0]/2):,0] #left\n",
    "\n",
    "        r = prediction_distance_r.copy()\n",
    "        l = prediction_distance_l.copy()\n",
    "\n",
    "        #-1~1사이 score\n",
    "        r = np.round(r) #반올림\n",
    "        r[r<-1]= -1\n",
    "        r[r>1] = 1\n",
    "\n",
    "\n",
    "        l = np.round(l)\n",
    "        l[l<-1]= -1\n",
    "        l[l>1] = 1    \n",
    "\n",
    "    #     print(l.shape)\n",
    "    #     print(r.shape)\n",
    "    #     print(info_df.shape)\n",
    "    #     print(result_info_df.shape)\n",
    "\n",
    "        inference_df['prediction_class_r'] = r\n",
    "        inference_df['prediction_class_l'] =l\n",
    "        inference_df['regression_distance_r'] = np.round(prediction_distance_r,3)\n",
    "        inference_df['regression_distance_l'] = np.round(prediction_distance_l,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        inference_df.to_csv(os.path.join(output_path_kfold, r'info.csv'))\n",
    "        total_info.append(inference_df)\n",
    "\n",
    "    total_df = pd.concat(total_info)\n",
    "    total_df.to_csv(os.path.join(output_path,'total.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "predictions_kfold = []\n",
    "labels_kfold = []\n",
    "distance_regression = [] \n",
    "\n",
    "total_info =[]\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# model_parm_name=\"D\"+depth+\"_\"+dropout_rat\n",
    "\n",
    "for kfold_idx, (train_idxs, test_idxs) in enumerate(kfold.split(x, y[:, 0])):\n",
    "    \n",
    "    log_df = pd.read_csv(os.path.join(output_path_kfold, r'log.csv'))\n",
    "    \n",
    "    \n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title(f'Learning Curves ({kfold_idx + 1:02d}/{kfold.n_splits:02d})')\n",
    "    plt.plot(log_df.loss)\n",
    "    plt.plot(log_df.val_loss)\n",
    "    plt.legend(('Train Loss', 'Validation Loss'))\n",
    "    \n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(log_df.classification_acc)\n",
    "    plt.plot(log_df.val_classification_acc)\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.legend(('Train Classification acc', 'Validation Classification acc'))\n",
    "    \n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(log_df.distance_prediction_acc)\n",
    "    plt.plot(log_df.val_distance_prediction_acc)\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.legend(('Train distance Classification acc', 'Validation distance Classification acc'))\n",
    "    \n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(log_df.regression_prediction_acc)\n",
    "    plt.plot(log_df.val_regression_prediction_acc)\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.legend(('Train regression Classification acc', 'Validation regression Classification acc'))\n",
    "\n",
    "    plt.show()\n",
    "    plt.style.use('seaborn-white')\n",
    "    print(f'Min. validation loss epoch: {log_df.val_loss.idxmin() + 1}')\n",
    "    print(f'Min. Classification MAE epoch: {log_df.val_classification_acc.idxmin() + 1}')\n",
    "    print(f'Min. distance validation MAE epoch: {log_df.val_distance_prediction_acc.idxmin() + 1}')\n",
    "    print(f'Min. regression validation MAE epoch: {log_df.val_regression_prediction_acc.idxmin() + 1}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    info_df = label_df.copy()\n",
    "    \n",
    "    result_info_df = info_df.iloc[test_idxs]\n",
    "    \n",
    "    inference_df = result_info_df.copy()\n",
    "    \n",
    "    # 4. Load a Model.\n",
    "    # ----------------------------------------\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.val_classification_acc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_results_df = pd.DataFrame(metrics, columns=('test_loss', 'test_mae'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = total_df['angle_class_r'].append(total_df['angle_class_l'])\n",
    "prediction =  total_df['prediction_class_r'].append(total_df['prediction_class_l'])\n",
    "data = np.array(data)\n",
    "prediction=np.array(prediction,dtype = int)\n",
    "\n",
    "cm = confusion_matrix(data, prediction, labels=[-1, 0, 1])\n",
    "\n",
    "print(cm)\n",
    "print(\"\")\n",
    "print(f'Accuracy: {(cm[0, 0] + cm[1, 1] + cm[2, 2]) / cm.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
